# mybatis配置
mybatis.mapper-locations = classpath:mapper/*.xml
mybatis.type-aliases-package = com.gondor.backend.pojo
logging.level.com.carry = DEBUG
mybatis.configuration.map-underscore-to-camel-case = true

#通用mapper
mapper.identity = MYSQL
mapper.mappers[0] = tk.mybatis.mapper.common.Mapper
mapper.mappers[1] = tk.mybatis.mapper.common.MySqlMapper
mapper.mappers[2] = tk.mybatis.mapper.common.IdsMapper
mapper.not-empty = true
mapper.enum-as-simple-type = true

#分页插件配置
pagehelper.helperDialect = mysql
pagehelper.reasonable = true
pagehelper.supportMethodsArguments = true
pagehelper.params = count=countSql

#数据源配置
spring.datasource.type = com.alibaba.druid.pool.DruidDataSource
spring.datasource.continue-on-error = false
spring.datasource.druid.initial-size = 50
spring.datasource.druid.min-idle = 50
spring.datasource.druid.max-active = 50
spring.datasource.druid.max-wait = 10000
spring.datasource.druid.time-between-eviction-runs-millis = 10000
spring.datasource.druid.min-evictable-idle-time-millis = 60000
spring.datasource.druid.validation-query = select 1
spring.datasource.druid.test-on-borrow = true
spring.datasource.druid.test-on-return = true
spring.datasource.druid.test-while-idle = true
spring.datasource.druid.pool-prepared-statements = false
spring.datasource.druid.filters = stat, wall
spring.datasource.druid.connection-properties = druid.stat.mergeSql=true;druid.stat.slowSqlMillis=1000
spring.datasource.druid.use-global-data-source-stat = true

#数据库
spring.datasource.druid.driver-class-name = com.mysql.cj.jdbc.Driver
spring.datasource.druid.url = jdbc:mysql://192.168.1.143:3306/northwind?useUnicode=true&useSSL=false&characterEncoding=utf8&serverTimezone=GMT%2B8
spring.datasource.druid.username = root
spring.datasource.druid.password = mjcy1989

# 客户端注册进eureka服务列表内（就是注册中心的地址）
eureka.client.service-url.defaultZone=http://192.168.1.121:8300/eureka/,http://192.168.1.122:8300/eureka/
eureka.instance.instance-id=${spring.application.name}:${server.port}
eureka.instance.prefer-ip-address=true
# 监控信息
info.app.name=${spring.application.name}
info.company.name=https://github.com/yousiyuan/
info.build.artifactId=@project.artifactId@
info.build.version=@project.version@
management.endpoints.web.exposure.include=health,info,hystrix.stream

# kafka配置消费者
spring.kafka.consumer.bootstrap-servers=192.168.1.191:9092,192.168.1.192:9092,192.168.1.193:9092
spring.kafka.consumer.group-id=gondor-backend-api
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# * 单次拉取的最大记录数
spring.kafka.consumer.max-poll-records=1
# * earliest: 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
# * latest: 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
# * none: topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false

# kafka配置监听器
# * 消费者并发启动个数（对应分区个数）也就是每个listener方法
spring.kafka.listener.concurrency = 3
spring.kafka.listener.poll-timeout = 3000
spring.kafka.listener.ack-mode=manual_immediate

# kafka配置生产者
spring.kafka.producer.bootstrap-servers=192.168.1.191:9092,192.168.1.192:9092,192.168.1.193:9092
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.buffer-memory = 524288
spring.kafka.producer.retries = 5
spring.kafka.producer.batch-size = 65536
spring.kafka.producer.acks=all
